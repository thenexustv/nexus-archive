# Plan 13: Podman Setup on Ubuntu 24.04 VPS

- **Date**: 2026-02-08
- **Status**: done

## Context

The VPS (grail) runs Ubuntu 24.04 LTS (upgraded from 22.04) and needs a container runtime for nexus-archive (and future sites/apps). Docker is not installed. Podman was chosen over Docker for its daemonless architecture — no background daemon process that can crash and take all containers down with it.

Ubuntu 24.04 ships **Podman 4.9.3** from the default repos, which includes all the modern features: Quadlet, `podman compose`, and pasta networking.

## Key concepts explained

### Rootless containers

By default, Podman runs containers as your regular (non-root) user. The container processes have no elevated privileges on the host — even if someone escapes the container, they're just an unprivileged user. This is a security advantage over Docker, which requires a root daemon.

For rootless to work, the OS needs to map fake "root inside the container" to a real unprivileged user on the host. This is done via **subuid/subgid** mappings — a range of user IDs reserved for your containers. Ubuntu sets these up automatically when you create a user, but we verify them in the setup steps below.

### Lingering

Normally, systemd kills all of a user's background processes when they log out (i.e., when you disconnect SSH). **Lingering** tells systemd to keep that user's services running even with no active sessions. Without it, your containers would stop every time you close your SSH connection.

### Quadlet

Quadlet is Podman's way of integrating with **systemd** (the system/service manager on Linux). Instead of manually running `podman run ...` commands, you write a simple `.container` file that describes what to run. Systemd then manages the container's lifecycle — starting it on boot, restarting it on failure, and providing logs via `journalctl`.

A `.container` file looks like a systemd unit but with a `[Container]` section instead of writing out the full `podman run` command yourself. When you run `systemctl --user daemon-reload`, Podman's Quadlet generator reads these files and creates real systemd services from them automatically.

Think of it as: **"systemd-native Docker Compose"** — one file per container, managed by the OS's service manager.

**Note:** Because the service is generated by Quadlet, `systemctl --user enable` will fail with "unit is transient or generated." This is expected — the `WantedBy=default.target` in the `.container` file handles auto-start automatically. Just use `daemon-reload` and `start`.

### Pasta networking

**Pasta** (Pack A Subtle Tap Abstraction) is the modern network backend for rootless Podman. It replaced the older `slirp4netns`. It's faster and copies the host's network config (DNS, routes) into the container automatically. You don't need to configure it — Podman 4.9+ uses it by default. For containers bound to localhost behind a reverse proxy, the performance difference is minimal, but it's the better default.

## Architecture

```
Internet → Apache (ports 80/443, TLS termination)
             → 127.0.0.1:4321 (rootless Podman container)
```

- Apache handles TLS and public-facing ports (configured in Plan 12)
- Containers bind to localhost high ports only
- Each app gets its own Quadlet `.container` file, managed as a systemd user service
- All containers run rootless under your regular user (`ryan`)

## Installation steps

### 1. Install Podman and Docker compatibility

```bash
sudo apt update
sudo apt install -y podman podman-compose podman-docker
sudo apt remove -y docker-compose
```

What each package does:
- **`podman`** — the container runtime
- **`podman-compose`** — reads `docker-compose.yml` files and translates them into Podman commands (uses direct CLI calls, no socket needed)
- **`podman-docker`** — installs a `/usr/bin/docker` symlink that points to `podman`, so `docker build`, `docker run`, `docker ps`, etc. all just work (they call Podman under the hood)

**Important:** Remove the old `docker-compose` package (Python-based v1). Ubuntu may have it installed, and `podman compose` will prefer it over `podman-compose` if it exists. The old v1 tries to connect to a Docker daemon socket and fails. After removing it, `podman compose` correctly delegates to `podman-compose`.

### 2. Enable lingering for your user

```bash
sudo loginctl enable-linger ryan
```

This tells systemd: "keep ryan's services running even when nobody is logged in." Without this, containers stop when you disconnect SSH.

Verify it worked:

```bash
loginctl show-user ryan -p Linger
# Expected: Linger=yes
```

### 3. Verify subuid/subgid mappings

These should already exist for your user, but verify:

```bash
grep ryan /etc/subuid
grep ryan /etc/subgid
```

If missing:

```bash
echo "ryan:100000:65536" | sudo tee -a /etc/subuid
echo "ryan:100000:65536" | sudo tee -a /etc/subgid
```

## Running nexus-archive

### Build and start (first time, using compose)

```bash
cd ~/services/nexus-archive

podman compose build
podman compose up -d
```

### Verify the container works

```bash
curl http://localhost:4321/api/health
# Expected: "ok"

podman ps
# Expected: nexus-archive container running
```

### Clean up the compose container

Before switching to Quadlet, stop and remove the compose-managed container:

```bash
podman compose down
```

### Set up Quadlet for auto-start

Create the Quadlet directory and file:

```bash
mkdir -p ~/.config/containers/systemd/
```

Create `~/.config/containers/systemd/nexus-archive.container`:

```ini
[Unit]
Description=nexus-archive (thenexus.tv)
After=local-fs.target

[Container]
Image=localhost/nexus-archive_nexus-archive:latest
PublishPort=127.0.0.1:4321:4321
Environment=HOST=0.0.0.0
Environment=PORT=4321
HealthCmd=curl -sf http://localhost:4321/api/health
HealthInterval=30s
HealthTimeout=5s
HealthRetries=3
HealthStartPeriod=10s

[Service]
Restart=always
TimeoutStartSec=900

[Install]
WantedBy=default.target
```

**About the image name:** `podman compose build` names the image `localhost/<directory>_<service>:latest`. Since the repo is cloned into `~/services/nexus-archive` and the compose service is called `nexus-archive`, the image is `localhost/nexus-archive_nexus-archive:latest`. If you clone into a differently-named directory, the prefix changes. Run `podman images` to confirm the exact name.

What each line does:
- **`Image=`** — which container image to run (the one built by `podman compose build`)
- **`PublishPort=127.0.0.1:4321:4321`** — bind port 4321 to localhost only (Apache proxies to this)
- **`Environment=`** — environment variables passed to the container
- **`HealthCmd=`** — how to check if the container is healthy
- **`Restart=always`** — systemd restarts the container if it crashes
- **`WantedBy=default.target`** — start on boot (handled by the Quadlet generator, no manual `enable` needed)

Activate it:

```bash
systemctl --user daemon-reload
systemctl --user start nexus-archive
```

**Do not run `systemctl --user enable`** — Quadlet-generated services handle auto-start via the `[Install]` section automatically. Running `enable` will fail with "unit is transient or generated," which is expected.

Check status:

```bash
systemctl --user status nexus-archive
```

View logs:

```bash
journalctl --user -u nexus-archive -f
```

### Compose vs Quadlet: when to use which

Once the Quadlet service is running, you no longer need `podman compose up`. Compose is still useful for **building** the image, but systemd via Quadlet handles **running** it:

| Action | Docker workflow | Podman + Quadlet workflow |
|--------|----------------|--------------------------|
| Build image | `docker compose build` | `podman compose build` |
| Start container | `docker compose up -d` | `systemctl --user start nexus-archive` |
| Stop container | `docker compose down` | `systemctl --user stop nexus-archive` |
| View logs | `docker compose logs -f` | `journalctl --user -u nexus-archive -f` |
| Auto-start on boot | Requires daemon + restart policy | Built-in (Quadlet + lingering) |
| Restart on crash | Requires daemon | Built-in (`Restart=always`) |

## Rebuilding after code changes

When you deploy a new version:

```bash
cd ~/services/nexus-archive

git pull
podman compose build
systemctl --user restart nexus-archive
```

The Quadlet service will stop the old container and start a new one from the freshly built image.

## Adding future sites/apps

For each new site:

1. Set up its repo with a `Dockerfile` and `docker-compose.yml`
2. Build the image: `podman compose build`
3. Create a new Quadlet file in `~/.config/containers/systemd/<app-name>.container` with a unique `PublishPort`
4. `systemctl --user daemon-reload && systemctl --user start <app-name>`
5. Add an Apache `ProxyPass` vhost for the new domain (like Plan 12)

Each container is independently managed by systemd. No shared daemon means one container's issues don't affect others.

## Gotchas encountered during setup

1. **Old `docker-compose` v1 conflicts with `podman compose`**: Ubuntu may have the Python-based `docker-compose` 1.29.2 installed. `podman compose` prefers it over `podman-compose`, but v1 tries to connect to a Docker daemon socket and fails. Fix: `sudo apt remove docker-compose`.

2. **Image name depends on directory name**: `podman compose build` names images as `localhost/<directory>_<service>:latest`. The Quadlet `Image=` line must match exactly. Run `podman images` to check.

3. **`systemctl --user enable` fails for Quadlet services**: This is expected. Quadlet-generated services are "transient" — the `WantedBy=default.target` in the `.container` file handles auto-start. Just use `daemon-reload` and `start`.

4. **Leftover containers block new ones**: If a previous `podman compose up` left a container with the same name, `podman compose up` again will fail with "name is already in use." Fix: `podman rm -f nexus-archive` or `podman compose down` first.

## Verification checklist

- `podman --version` — shows 4.9.3
- `docker --version` — shows podman (via podman-docker symlink)
- `podman compose version` — delegates to podman-compose 1.0.6
- `loginctl show-user ryan -p Linger` — shows `Linger=yes`
- `systemctl --user status nexus-archive` — active (running)
- `curl http://localhost:4321/api/health` — returns "ok"
- Container auto-starts after `sudo reboot`
- Apache proxies to container successfully (Plan 12 verification)
